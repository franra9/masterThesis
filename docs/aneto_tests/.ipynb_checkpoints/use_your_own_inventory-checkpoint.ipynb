{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using your our own glacier inventory with OGGM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The Randolph Glacier Inventory](https://www.glims.org/RGI/) is a key dataset to model glaciers at any scale: it includes outlines of the extent of each glacier in the world, an information that is critical in figuring out how much a particular glacier might contribute to rising sea level. These glacier outlines are the starting point of any simulation in OGGM. The RGI's latest version (v6), as well as v5, are provided and supported by OGGM (see the [documentation](https://oggm.readthedocs.io/en/latest/input-data.html#glacier-outlines-and-intersects)). However, there are [several issues](https://rgitools.readthedocs.io/en/latest/known-issues.html) in the RGI that might make you want to use your own corrected glacier outlines. \n",
    "\n",
    "This notebook describes how to feed OGGM with them. We will show you three case studies about how to give any geometry to OGGM and avoid errors of incompatibility between your shapefile and the model framework.\n",
    "\n",
    "We have three case studies which should cover a number of applications:\n",
    "1. [Dividing a glacier into smaller entities](#case1) (common case, useful for poorly outlined glaciers, which are in reality separate dynamical entities)\n",
    "2. [Merging two glaciers together](#case2) (useful for tidewater glaciers in particular, not much elsewhere)\n",
    "3. [Start from a completely independent inventory](#case3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TLDR;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use custom data to feed OGGM with, you should:\n",
    "- **make a shapefile that resembles the RGI one: same attributes, and the glacier geometries should be in lon/lat projection**. The most important attribute is `geometry`, of course, but others are used by OGGM as well: refer to [the OGGM documentation](https://docs.oggm.org/en/stable/input-data.html#glacier-outlines-and-intersects) to decide which ones. The RGI documentation (found in the RGI directory after download) is useful as well! We also have a useful function (`oggm.utils.cook_rgidf`) which can help you with that.\n",
    "- **compute and use a new [glacier interesects](https://rgitools.readthedocs.io/en/latest/tools.html#glacier-intersects) file**, or make sure you don't need one and disable this option in OGGM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of an RGI file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='case3'></a>\n",
    "## Case 3: start from a completely independent inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OGGM (since version 1.5.3) now offers a function (`utils.cook_rgidf()`) to make it easier of using a non-RGI glacier inventory in OGGM. Now, let's use a non-RGI glacier inventory from the second Chinese glacier inventory (CGI2, https://doi.org/10.3189/2015JoG14J209) to show how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the sample CGI2 glacier inventory and see what it looks like\n",
    "from oggm import utils\n",
    "import geopandas as gpd\n",
    "cgidf = gpd.read_file(utils.get_demo_file('cgi2.shp'))\n",
    "cgidf\n",
    "\n",
    "cgidf_a = gpd.read_file('/home/francesc/data/aneto_glacier/Contornos/Aneto2011.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha! There are some Chinese characters! But it should not influence our work. Now, let's try with the simplest case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RGIId</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>GLIMSId</th>\n",
       "      <th>BgnDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>O1Region</th>\n",
       "      <th>O2Region</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>...</th>\n",
       "      <th>Lmax</th>\n",
       "      <th>Status</th>\n",
       "      <th>Connect</th>\n",
       "      <th>Form</th>\n",
       "      <th>TermType</th>\n",
       "      <th>Surging</th>\n",
       "      <th>Linkages</th>\n",
       "      <th>check_geom</th>\n",
       "      <th>Name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RGI60-11.03208</td>\n",
       "      <td>0.649519</td>\n",
       "      <td>42.638706</td>\n",
       "      <td></td>\n",
       "      <td>2011</td>\n",
       "      <td>9999999</td>\n",
       "      <td>11</td>\n",
       "      <td>02</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>POLYGON ((0.64709 42.64397, 0.64726 42.64394, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            RGIId    CenLon     CenLat GLIMSId BgnDate  EndDate O1Region  \\\n",
       "0  RGI60-11.03208  0.649519  42.638706            2011  9999999       11   \n",
       "\n",
       "  O2Region    Area    Zmin  ...  Lmax  Status  Connect  Form  TermType  \\\n",
       "0       02 -9999.0 -9999.0  ... -9999       0        0     0         0   \n",
       "\n",
       "   Surging  Linkages  check_geom  Name  \\\n",
       "0        0         1        None         \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((0.64709 42.64397, 0.64726 42.64394, ...  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgidf_simple = utils.cook_rgidf(cgidf, o1_region='13')\n",
    "rgidf_simple\n",
    "\n",
    "rgidf_simple_a = utils.cook_rgidf(cgidf_a, ids=[int('3208')], o1_region='11', o2_region='02', bgndate='2011') #id_suffix aneto glacier\n",
    "rgidf_simple_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we fake all of the columns values except for `geometry`. With this `rgidf_simple`, we can handle most of the OGGM procedure after set `cfg.PARAMS['use_rgi_area'] = False`. Let's have a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 13:28:09: oggm.cfg: Reading default parameters from the OGGM `params.cfg` configuration file.\n",
      "2022-06-09 13:28:09: oggm.cfg: Multiprocessing switched OFF according to the parameter file.\n",
      "2022-06-09 13:28:09: oggm.cfg: Multiprocessing: using all available processors (N=8)\n",
      "2022-06-09 13:28:10: oggm.cfg: Multiprocessing switched ON after user settings.\n",
      "2022-06-09 13:28:10: oggm.cfg: PARAMS['use_rgi_area'] changed from `True` to `False`.\n",
      "2022-06-09 13:28:10: oggm.cfg: PARAMS['use_intersects'] changed from `True` to `False`.\n",
      "2022-06-09 13:28:10: oggm.workflow: Execute entity tasks [GlacierDirectory] on 5 glaciers\n",
      "2022-06-09 13:28:10: oggm.workflow: Execute entity tasks [GlacierDirectory] on 1 glaciers\n",
      "2022-06-09 13:28:10: oggm.utils: Applying global task compile_glacier_statistics on 1 glaciers\n",
      "2022-06-09 13:28:10: oggm.workflow: Execute entity tasks [glacier_statistics] on 1 glaciers\n",
      "2022-06-09 13:28:10: oggm.utils: (RGI60-11.03208) glacier_statistics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rgi_region</th>\n",
       "      <th>rgi_subregion</th>\n",
       "      <th>name</th>\n",
       "      <th>cenlon</th>\n",
       "      <th>cenlat</th>\n",
       "      <th>rgi_area_km2</th>\n",
       "      <th>rgi_year</th>\n",
       "      <th>glacier_type</th>\n",
       "      <th>terminus_type</th>\n",
       "      <th>is_tidewater</th>\n",
       "      <th>status</th>\n",
       "      <th>error_task</th>\n",
       "      <th>error_msg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rgi_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RGI60-11.03208</th>\n",
       "      <td>11</td>\n",
       "      <td>11-02</td>\n",
       "      <td></td>\n",
       "      <td>0.649519</td>\n",
       "      <td>42.638706</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2011</td>\n",
       "      <td>Glacier</td>\n",
       "      <td>Land-terminating</td>\n",
       "      <td>False</td>\n",
       "      <td>Glacier or ice cap</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               rgi_region rgi_subregion name    cenlon     cenlat  \\\n",
       "rgi_id                                                              \n",
       "RGI60-11.03208         11         11-02       0.649519  42.638706   \n",
       "\n",
       "                rgi_area_km2  rgi_year glacier_type     terminus_type  \\\n",
       "rgi_id                                                                  \n",
       "RGI60-11.03208         0.625      2011      Glacier  Land-terminating   \n",
       "\n",
       "                is_tidewater              status error_task error_msg  \n",
       "rgi_id                                                                 \n",
       "RGI60-11.03208         False  Glacier or ice cap       None      None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from oggm import cfg, workflow\n",
    "\n",
    "cfg.initialize()\n",
    "cfg.PARAMS['use_multiprocessing'] = True\n",
    "cfg.PARAMS['use_rgi_area'] = False\n",
    "cfg.PARAMS['use_intersects'] = False\n",
    "cfg.PATHS['working_dir'] = utils.gettempdir(dirname='cook_rgidf', reset=True)\n",
    "gdirs = workflow.init_glacier_directories(rgidf_simple)\n",
    "\n",
    "cfg.PATHS['working_dir'] = utils.gettempdir(dirname='OGGM-sfc-type', reset=True)\n",
    "gdirs = workflow.init_glacier_directories(rgidf_simple_a)\n",
    "\n",
    "# The tasks below require downloading new data - we comment them for the tutorial, but it should work for you!\n",
    "# workflow.gis_prepro_tasks(gdirs)\n",
    "# workflow.download_ref_tstars('https://cluster.klima.uni-bremen.de/~oggm/ref_mb_params/oggm_v1.4/RGIV62/CRU/centerlines/qc3/pcp2.5')\n",
    "# workflow.climate_tasks(gdirs)\n",
    "# workflow.inversion_tasks(gdirs)\n",
    "\n",
    "utils.compile_glacier_statistics(gdirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the information in the original glacier inventory also covered what RGI need, but with different name. For example, both CGI2 and RGI include Lon-lat coordinate to indicate the location of the glacier but with different names. CGI2 used `Glc_Long` and `Glc_Lati`, while RGI6 used `CenLon` and `CenLat`. Also, CGI2 include glacier area information with name `Glc_Area`, while RGI named glacier area as `Area`. If we want to keep those values but rename them following RGI, we can use the `assign_column_values` keyword argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RGIId</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>GLIMSId</th>\n",
       "      <th>BgnDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>O1Region</th>\n",
       "      <th>O2Region</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>...</th>\n",
       "      <th>Lmax</th>\n",
       "      <th>Status</th>\n",
       "      <th>Connect</th>\n",
       "      <th>Form</th>\n",
       "      <th>TermType</th>\n",
       "      <th>Surging</th>\n",
       "      <th>Linkages</th>\n",
       "      <th>check_geom</th>\n",
       "      <th>Name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RGI60-13.00001</td>\n",
       "      <td>84.892252</td>\n",
       "      <td>43.502473</td>\n",
       "      <td>G084892E43502N</td>\n",
       "      <td>20009999</td>\n",
       "      <td>9999999</td>\n",
       "      <td>13</td>\n",
       "      <td>01</td>\n",
       "      <td>4410738.3</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>POLYGON ((84.88765 43.51793, 84.88820 43.51803...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RGI60-13.00002</td>\n",
       "      <td>94.299430</td>\n",
       "      <td>35.671728</td>\n",
       "      <td>G094299E35672N</td>\n",
       "      <td>20009999</td>\n",
       "      <td>9999999</td>\n",
       "      <td>13</td>\n",
       "      <td>01</td>\n",
       "      <td>2569748.4</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>POLYGON ((94.28628 35.67243, 94.28669 35.67247...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RGI60-13.00003</td>\n",
       "      <td>96.289832</td>\n",
       "      <td>29.879834</td>\n",
       "      <td>G096290E29880N</td>\n",
       "      <td>20009999</td>\n",
       "      <td>9999999</td>\n",
       "      <td>13</td>\n",
       "      <td>01</td>\n",
       "      <td>320096.7</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>POLYGON ((96.28739 29.88241, 96.28744 29.88235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RGI60-13.00004</td>\n",
       "      <td>92.234420</td>\n",
       "      <td>32.781958</td>\n",
       "      <td>G092234E32782N</td>\n",
       "      <td>20009999</td>\n",
       "      <td>9999999</td>\n",
       "      <td>13</td>\n",
       "      <td>01</td>\n",
       "      <td>969356.4</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>POLYGON ((92.23549 32.77855, 92.23501 32.77851...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RGI60-13.00005</td>\n",
       "      <td>97.340135</td>\n",
       "      <td>29.195439</td>\n",
       "      <td>G097340E29195N</td>\n",
       "      <td>20009999</td>\n",
       "      <td>9999999</td>\n",
       "      <td>13</td>\n",
       "      <td>01</td>\n",
       "      <td>839757.2</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>POLYGON ((97.34704 29.18993, 97.34703 29.18993...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            RGIId     CenLon     CenLat         GLIMSId   BgnDate  EndDate  \\\n",
       "0  RGI60-13.00001  84.892252  43.502473  G084892E43502N  20009999  9999999   \n",
       "1  RGI60-13.00002  94.299430  35.671728  G094299E35672N  20009999  9999999   \n",
       "2  RGI60-13.00003  96.289832  29.879834  G096290E29880N  20009999  9999999   \n",
       "3  RGI60-13.00004  92.234420  32.781958  G092234E32782N  20009999  9999999   \n",
       "4  RGI60-13.00005  97.340135  29.195439  G097340E29195N  20009999  9999999   \n",
       "\n",
       "  O1Region O2Region       Area    Zmin  ...  Lmax  Status  Connect  Form  \\\n",
       "0       13       01  4410738.3 -9999.0  ... -9999       0        0     0   \n",
       "1       13       01  2569748.4 -9999.0  ... -9999       0        0     0   \n",
       "2       13       01   320096.7 -9999.0  ... -9999       0        0     0   \n",
       "3       13       01   969356.4 -9999.0  ... -9999       0        0     0   \n",
       "4       13       01   839757.2 -9999.0  ... -9999       0        0     0   \n",
       "\n",
       "   TermType  Surging  Linkages  check_geom  Name  \\\n",
       "0         0        0         1        None         \n",
       "1         0        0         1        None         \n",
       "2         0        0         1        None         \n",
       "3         0        0         1        None         \n",
       "4         0        0         1        None         \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((84.88765 43.51793, 84.88820 43.51803...  \n",
       "1  POLYGON ((94.28628 35.67243, 94.28669 35.67247...  \n",
       "2  POLYGON ((96.28739 29.88241, 96.28744 29.88235...  \n",
       "3  POLYGON ((92.23549 32.77855, 92.23501 32.77851...  \n",
       "4  POLYGON ((97.34704 29.18993, 97.34703 29.18993...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgidf_save_columns = utils.cook_rgidf(cgidf, o1_region='13', assign_column_values={'Glc_Long': 'CenLon', 'Glc_Lati': 'CenLat', 'Glc_Area': 'Area', 'GLIMS_ID': 'GLIMSId'})\n",
    "rgidf_save_columns\n",
    "\n",
    "#rgidf_save_columns_a = utils.cook_rgidf(cgidf_a, o1_region='11', assign_column_values={'cenlon': 'CenLon', 'cenlat': 'CenLat'})\n",
    "#rgidf_save_columns_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems perfect! However, the glacier area in CGI2 is in $m^2$, but it is in $km^2$ for RGI. So, we need to correct the `Area` values right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<oggm.GlacierDirectory>\n",
       "   RGI id: RGI60-11.03208\n",
       "   Region: 11: Central Europe\n",
       "   Subregion: 11-02: Southern and Eastern Europe     \n",
       "   Glacier type: Glacier\n",
       "   Terminus type: Land-terminating\n",
       "   Status: Glacier or ice cap\n",
       "   Area: 0.625 km2\n",
       "   Lon, Lat: (0.6495185230130673, 42.63870591716959)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgidf_save_columns['Area'] = rgidf_save_columns.Area * 1e-6\n",
    "rgidf_save_columns.Area\n",
    "\n",
    "#rgidf_save_columns_a['Area'] = rgidf_simple_a.area\n",
    "#rgidf_save_columns_a.Area\n",
    "\n",
    "rgidf_simple_a.to_crs('EPSG:25831').area #in m²\n",
    "rgidf_simple_a['Area'] = rgidf_simple_a.to_crs('EPSG:25831').area * 1e-6 #in km²\n",
    "rgidf_simple_a\n",
    "gdirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "\n",
    "Despite that `cook_rgidf()` can handle most of the cases for OGGM, there are some limitations. Here, we try to point out some of cases in which the `rgidf` sourced from `cook_rgidf()` might get you in trouble:\n",
    "- in `cook_rgidf()`, we assign the glacier form with '0' (Glacier) for all of the glaciers in the original data. OGGM assigns different parameters for glaciers (form '0') and ice caps (form '1').\n",
    "- `termtype` was also assign as '0' which means 'land-terminating'. Here again, OGGM treats 'Marine-terminating' glaciers differently (see ['Frontal ablation'](https://docs.oggm.org/en/stable/frontal-ablation.html)). \n",
    "\n",
    "For these kinds of attribution, there is nothing we can do automatically. Users need to assign the right values according the actual condition of their glaciers, if the attribution is important to their use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "- return to the [OGGM documentation](https://docs.oggm.org)\n",
    "- back to the [table of contents](welcome.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 13:28:10: oggm.cfg: Reading default parameters from the OGGM `params.cfg` configuration file.\n",
      "2022-06-09 13:28:10: oggm.cfg: Multiprocessing switched OFF according to the parameter file.\n",
      "2022-06-09 13:28:10: oggm.cfg: Multiprocessing: using all available processors (N=8)\n",
      "2022-06-09 13:28:10: oggm.cfg: PARAMS['use_intersects'] changed from `True` to `False`.\n",
      "2022-06-09 13:28:10: oggm.cfg: PARAMS['hydro_month_nh'] changed from `10` to `1`.\n",
      "2022-06-09 13:28:10: oggm.workflow: Execute entity tasks [GlacierDirectory] on 1 glaciers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<oggm.GlacierDirectory>\n",
       "  RGI id: RGI60-11.03208\n",
       "  Region: 11: Central Europe\n",
       "  Subregion: 11-02: Southern and Eastern Europe     \n",
       "  Glacier type: Glacier\n",
       "  Terminus type: Land-terminating\n",
       "  Status: Glacier or ice cap\n",
       "  Area: 0.626 km2\n",
       "  Lon, Lat: (0.6495185230130673, 42.63870591716959)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skimage\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from numpy.testing import assert_allclose\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "from IPython.core.pylabtools import figsize\n",
    "import os\n",
    "\n",
    "import oggm\n",
    "from oggm import cfg, utils, workflow, tasks, graphics, entity_task\n",
    "from oggm.utils import date_to_floatyear\n",
    "from oggm.shop import gcm_climate\n",
    "from oggm.core import massbalance, flowline, climate\n",
    "\n",
    "import logging\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "cfg.initialize() #logging_level='WARNING'\n",
    "cfg.PARAMS['use_multiprocessing'] = False\n",
    "cfg.PARAMS['continue_on_error'] = False\n",
    "cfg.PATHS['working_dir'] = utils.gettempdir(dirname='OGGM-sfc-type')#, reset=True)\n",
    "cfg.PARAMS['use_intersects'] = False\n",
    "\n",
    "# use Huss flowlines\n",
    "base_url = ('https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.4/'\n",
    "            'L1-L2_files/elev_bands')\n",
    "\n",
    "# import the MBsandbox modules\n",
    "from MBsandbox.mbmod_daily_oneflowline import (process_w5e5_data, BASENAMES, MultipleFlowlineMassBalance_TIModel, TIModel_Sfc_Type, TIModel_Sfc_Type_point)\n",
    "from MBsandbox.help_func import minimize_bias_geodetic, minimize_winter_mb_brentq_geod_via_pf\n",
    "\n",
    "\n",
    "# FRA: WHY GEODETIC MB STARTS ON JAN AND NOT SEP?\n",
    "cfg.PARAMS['hydro_month_nh']=1  # to calibrate to the geodetic estimates we need calendar years !!!\n",
    "\n",
    "#df = ['RGI60-11.03208']  # here we select Aneto glacier!\n",
    "\n",
    "gdirs = workflow.init_glacier_directories(rgidf_simple_a,prepro_base_url=base_url)\n",
    "gdir = gdirs[0]\n",
    "gdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 13:28:11: MBsandbox.mbmod_daily_oneflowline: (RGI60-11.03208) process_w5e5_data\n",
      "2022-06-09 13:28:11: oggm.utils: No known hash for cluster.klima.uni-bremen.de/~lschuster/w5e5v2.0/flattened/daily/w5e5v2.0_tas_global_daily_flat_glaciers_1979_2019.nc\n",
      "2022-06-09 13:28:11: oggm.utils: No known hash for cluster.klima.uni-bremen.de/~lschuster/w5e5v2.0/flattened/daily/w5e5v2.0_pr_global_daily_flat_glaciers_1979_2019.nc\n",
      "2022-06-09 13:28:11: oggm.utils: No known hash for cluster.klima.uni-bremen.de/~lschuster/w5e5v2.0/flattened/daily/w5e5v2.0_glacier_invariant_flat.nc\n",
      "2022-06-09 13:28:23: oggm.utils: /home/francesc/data/OGGM/download_cache/cluster.klima.uni-bremen.de/~oggm/climate/era5/monthly/vdr/ERA5_lapserates_monthly.nc verified successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<oggm.GlacierDirectory>\n",
       "  RGI id: RGI60-11.03208\n",
       "  Region: 11: Central Europe\n",
       "  Subregion: 11-02: Southern and Eastern Europe     \n",
       "  Glacier type: Glacier\n",
       "  Terminus type: Land-terminating\n",
       "  Status: Glacier or ice cap\n",
       "  Area: 0.626 km2\n",
       "  Lon, Lat: (0.6495185230130673, 42.63870591716959)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the applied resolution of the precipitation and temperature climate dataset\n",
    "temporal_resol = 'daily'\n",
    "baseline_climate = 'W5E5' \n",
    "process_w5e5_data(gdir, temporal_resol=temporal_resol,\n",
    "                  climate_type=baseline_climate)\n",
    "\n",
    "# let's get the heights and widths of the inversion (we use here the elevation-band flowline!)\n",
    "#h, w = gdir.get_inversion_flowline_hw()\n",
    "#fls = gdir.read_pickle('inversion_flowlines')\n",
    "gdir\n",
    "#h, w = gdir.get_inversion_flowline_hw()\n",
    "#fls = gdir.read_pickle('inversion_flowlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MB model options: \n",
    "# we just use the most complicated ones: \n",
    "mb_type = 'mb_real_daily'  # daily climate resolution \n",
    "grad_type = 'var_an_cycle'  # a variable temperature lapse rate (cte between the years but changing spatially and between the months)\n",
    "melt_f_update = 'monthly'  # how often the melt factor is updated to distinguish between different snow / firn ages\n",
    "melt_f_change = 'neg_exp'  # the way how the melt factor changes over time \n",
    "tau_e_fold_yr = 1  # how fast the melt factor of snow converges to the ice melt factor \n",
    "kwargs_for_TIModel_Sfc_Type = {'melt_f_update':melt_f_update, 'melt_f_change': melt_f_change, 'tau_e_fold_yr':tau_e_fold_yr}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_f = 200\n",
    "pf = 1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dummy lfowlines\n",
    "# let's get the heights and widths of the inversion (we use here the elevation-band flowline!)\n",
    "h, w = np.array([3000,3001]), np.array([3000,3001]) #gdir.get_inversion_flowline_hw()\n",
    "#fls = gdir.read_pickle('inversion_flowlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<oggm.MassBalanceModel>\n",
       "  Class: TIModel_Sfc_Type_point\n",
       "  Attributes:\n",
       "    - residual: 0\n",
       "    - t_solid: 0\n",
       "    - t_liq: 2\n",
       "    - t_melt: 0\n",
       "    - N: 100\n",
       "    - mb_type: mb_real_daily\n",
       "    - loop: False\n",
       "    - grad_type: var_an_cycle\n",
       "    - rho: 900.0\n",
       "    - hemisphere: nh\n",
       "    - repeat: False\n",
       "    - SEC_IN_YEAR: 31536000\n",
       "    - SEC_IN_MONTH: 2628000\n",
       "    - SEC_IN_DAY: 86400\n",
       "    - temp_std: nan\n",
       "    - ref_hgt: 1643.0\n",
       "    - uncorrected_ref_hgt: 1643.0\n",
       "    - ys: 1979\n",
       "    - ye: 2019\n",
       "    - fpath: /tmp/OGGM/OGGM-sfc-type/per_glacier/RGI60-11/RGI60-11.03/RGI60-11.03208/climate_historical_daily_W5E5.nc\n",
       "    - hbins: nan\n",
       "    - interpolation_optim: False\n",
       "    - tau_e_fold_yr: 1\n",
       "    - melt_f_change: neg_exp\n",
       "    - melt_f_ratio_snow_to_ice: 0.5\n",
       "    - melt_f_update: monthly\n",
       "    - spinup_yrs: 6\n",
       "    - first_snow_bucket: 0\n",
       "    - inv_heights: 3000\n",
       "    - check_availability: True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with normal spinup for 6 years\n",
    "mb_mod_monthly_0_5_m = TIModel_Sfc_Type_point(gdir, melt_f, mb_type=mb_type, grad_type = grad_type,\n",
    "                                        prcp_fac=pf,\n",
    "                                        melt_f_update=melt_f_update,\n",
    "                                        melt_f_change = melt_f_change, \n",
    "                                        tau_e_fold_yr = tau_e_fold_yr,\n",
    "                                        baseline_climate=baseline_climate)\n",
    "# default temp. bias is 0 !\n",
    "mb_mod_monthly_0_5_m.temp_bias\n",
    "\n",
    "mb_mod_monthly_0_5_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can calibrate the melt factor (same as mu_star in OGGM default) to match e.g. the geodetic MB observed by Zaragoza people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get the observed geodetic data for calibration\n",
    "# FRA THIS IS A MEAN OVER THE WHOLE GLACIER\n",
    "mb_geodetic = np.array(-800) # from zaragoza people 2011-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redefine h and w for fun\n",
    "h = np.array([3000])\n",
    "w = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005.0\n",
      "2005.0833333333333\n",
      "2005.1666666666667\n",
      "2005.25\n",
      "2005.3333333333333\n",
      "2005.4166666666667\n",
      "2005.5\n",
      "2005.5833333333333\n",
      "2005.6666666666667\n",
      "2005.75\n",
      "2005.8333333333333\n",
      "2005.9166666666667\n",
      "2006.0\n",
      "2006.0833333333333\n",
      "2006.1666666666667\n",
      "2006.25\n",
      "2006.3333333333333\n",
      "2006.4166666666667\n",
      "2006.5\n",
      "2006.5833333333333\n",
      "2006.6666666666667\n",
      "2006.75\n",
      "2006.8333333333333\n",
      "2006.9166666666667\n",
      "2007.0\n",
      "2007.0833333333333\n",
      "2007.1666666666667\n",
      "2007.25\n",
      "2007.3333333333333\n",
      "2007.4166666666667\n",
      "2007.5\n",
      "2007.5833333333333\n",
      "2007.6666666666667\n",
      "2007.75\n",
      "2007.8333333333333\n",
      "2007.9166666666667\n",
      "2008.0\n",
      "2008.0833333333333\n",
      "2008.1666666666667\n",
      "2008.25\n",
      "2008.3333333333333\n",
      "2008.4166666666667\n",
      "2008.5\n",
      "2008.5833333333333\n",
      "2008.6666666666667\n",
      "2008.75\n",
      "2008.8333333333333\n",
      "2008.9166666666667\n",
      "2009.0\n",
      "2009.0833333333333\n",
      "2009.1666666666667\n",
      "2009.25\n",
      "2009.3333333333333\n",
      "2009.4166666666667\n",
      "2009.5\n",
      "2009.5833333333333\n",
      "2009.6666666666667\n",
      "2009.75\n",
      "2009.8333333333333\n",
      "2009.9166666666667\n",
      "2010.0\n",
      "2010.0833333333333\n",
      "2010.1666666666667\n",
      "2010.25\n",
      "2010.3333333333333\n",
      "2010.4166666666667\n",
      "2010.5\n",
      "2010.5833333333333\n",
      "2010.6666666666667\n",
      "2010.75\n",
      "2010.8333333333333\n",
      "2010.9166666666667\n",
      "2011.0\n",
      "2011.0833333333333\n",
      "2011.1666666666667\n",
      "2011.25\n",
      "2011.3333333333333\n",
      "2011.4166666666667\n",
      "2011.5\n",
      "2011.5833333333333\n",
      "2011.6666666666667\n",
      "2011.75\n",
      "2011.8333333333333\n",
      "2011.9166666666667\n",
      "2012.0\n",
      "2012.0833333333333\n",
      "2012.1666666666667\n",
      "2012.25\n",
      "2012.3333333333333\n",
      "2012.4166666666667\n",
      "2012.5\n",
      "2012.5833333333333\n",
      "2012.6666666666667\n",
      "2012.75\n",
      "2012.8333333333333\n",
      "2012.9166666666667\n",
      "2013.0\n",
      "2013.0833333333333\n",
      "2013.1666666666667\n",
      "2013.25\n",
      "2013.3333333333333\n",
      "2013.4166666666667\n",
      "2013.5\n",
      "2013.5833333333333\n",
      "2013.6666666666667\n",
      "2013.75\n",
      "2013.8333333333333\n",
      "2013.9166666666667\n",
      "2014.0\n",
      "2014.0833333333333\n",
      "2014.1666666666667\n",
      "2014.25\n",
      "2014.3333333333333\n",
      "2014.4166666666667\n",
      "2014.5\n",
      "2014.5833333333333\n",
      "2014.6666666666667\n",
      "2014.75\n",
      "2014.8333333333333\n",
      "2014.9166666666667\n",
      "2015.0\n",
      "2015.0833333333333\n",
      "2015.1666666666667\n",
      "2015.25\n",
      "2015.3333333333333\n",
      "2015.4166666666667\n",
      "2015.5\n",
      "2015.5833333333333\n",
      "2015.6666666666667\n",
      "2015.75\n",
      "2015.8333333333333\n",
      "2015.9166666666667\n",
      "2016.0\n",
      "2016.0833333333333\n",
      "2016.1666666666667\n",
      "2016.25\n",
      "2016.3333333333333\n",
      "2016.4166666666667\n",
      "2016.5\n",
      "2016.5833333333333\n",
      "2016.6666666666667\n",
      "2016.75\n",
      "2016.8333333333333\n",
      "2016.9166666666667\n",
      "2017.0\n",
      "2017.0833333333333\n",
      "2017.1666666666667\n",
      "2017.25\n",
      "2017.3333333333333\n",
      "2017.4166666666667\n",
      "2017.5\n",
      "2017.5833333333333\n",
      "2017.6666666666667\n",
      "2017.75\n",
      "2017.8333333333333\n",
      "2017.9166666666667\n",
      "2018.0\n",
      "2018.0833333333333\n",
      "2018.1666666666667\n",
      "2018.25\n",
      "2018.3333333333333\n",
      "2018.4166666666667\n",
      "2018.5\n",
      "2018.5833333333333\n",
      "2018.6666666666667\n",
      "2018.75\n",
      "2018.8333333333333\n",
      "2018.9166666666667\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "f(a) and f(b) must have different signs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_232132/701240448.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0myears\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2011\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2019\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m melt_f_opt_0_5_m = scipy.optimize.brentq(minimize_bias_geodetic, \n\u001b[0m\u001b[1;32m      3\u001b[0m                                          \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# minimum and maximum value of melt_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                          xtol=0.01, args=(mb_mod_monthly_0_5_m,\n\u001b[1;32m      5\u001b[0m                                                       \u001b[0mmb_geodetic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_mb/lib/python3.10/site-packages/scipy/optimize/_zeros_py.py\u001b[0m in \u001b[0;36mbrentq\u001b[0;34m(f, a, b, args, xtol, rtol, maxiter, full_output, disp)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrtol\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0m_rtol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rtol too small (%g < %g)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_zeros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_brentq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: f(a) and f(b) must have different signs"
     ]
    }
   ],
   "source": [
    "years = np.arange(2011, 2020, 1)\n",
    "melt_f_opt_0_5_m = scipy.optimize.brentq(minimize_bias_geodetic, \n",
    "                                         10, 1000, # minimum and maximum value of melt_f\n",
    "                                         xtol=0.01, args=(mb_mod_monthly_0_5_m,\n",
    "                                                      mb_geodetic,\n",
    "                                                      h, w, pf, False,\n",
    "                                                      years,\n",
    "                                                      False, True, # yes, do spinup before\n",
    "                                                      ), disp=True)\n",
    "# change the melt_f to the newly calibrated one\n",
    "#mb_mod_monthly_0_5_m.melt_f = melt_f_opt_0_5_m\n",
    "#spec_0_5_m = mb_mod_monthly_0_5_m.get_specific_mb(year=years, heights=h, widths=w)\n",
    "# check if the calibration has worked as we expect:\n",
    "#np.testing.assert_allclose(spec_0_5_m.mean(), mb_geodetic, rtol = 1e-4)\n",
    "#print(melt_f_opt_0_5_m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.optimize.brentq?\n",
    "minimize_bias_geodetic?\n",
    "#mb_mod_monthly_0_5_m.get_specific_mb?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the \"raw\" climate that is used for the glacier during the calibration time period (without local downscaling by applying a multiplicative precipitation correction factor or a temperature bias)\n",
    "fpath_climate = gdir.get_filepath('climate_historical', filesuffix='_daily_W5E5')\n",
    "ds_clim = xr.open_dataset(fpath_climate)\n",
    "ds_clim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we just applied an arbitrary precipitation factor. You could calibrate the precipitation factor to match other observations, for example the winter mass-balance, by minimizing both, geodetic bias and winter MB, using melt_f and prcp-fac as parameters to calibrate (via help_func/minimize_winter_mb_brentq_geod_via_pf). However, as your glacier is no reference glacier, you can not use this approach!\n",
    "\n",
    "FRA WHY CAN I NOT CALIBRATE THE PRECIPITAITON FACTOR?\n",
    "\n",
    "Instead you could use a relationship that was found for reference glaciers that have winter MB available:\n",
    "\n",
    "*    glaciers with stronger winter precipitation do have rather larger precipitation factors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are in the NH, so to get winter prcp we need October to April\n",
    "ds_prcp_winter = ds_clim.prcp.where(ds_clim.prcp['time.month'].isin([10, 11, 12, 1, 2, 3, 4]),\n",
    "                                                           drop=True).mean().values\n",
    "# mean winter prcp in kg m-2, mean over 1979-2020\n",
    "ds_prcp_winter\n",
    "\n",
    "### --> that's per day, it makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_log_multiplied = -0.988689\n",
    "b_intercept = 4.004772\n",
    "def log_func(x, a, b):\n",
    "    r = a*np.log(x) +b\n",
    "    # don't allow extremely low/high prcp. factors!!!\n",
    "    if np.shape(r) == ():\n",
    "        if r > 10:\n",
    "            r = 10\n",
    "        if r<0.1:\n",
    "            r=0.1\n",
    "    else:\n",
    "        r[r>10] = 10\n",
    "        r[r<0.1] = 0.1\n",
    "    return r\n",
    "\n",
    "winter_prcp_values = np.arange(0.1, 20,0.05)\n",
    "plt.plot(winter_prcp_values, log_func(winter_prcp_values, a_log_multiplied, b_intercept), label='fitted precipitation factor relation to winter\\nprecipitation (found from 114 reference\\nglaciers where winter MB was matched)')\n",
    "fit_prcp_fac_aneto = log_func(ds_prcp_winter, a_log_multiplied, b_intercept)\n",
    "plt.axvline(ds_prcp_winter, ls=':', color='grey', label=f'Aneto glacier, fitted prcp_fac={fit_prcp_fac_aneto:.2f}')\n",
    "plt.axhline(fit_prcp_fac_aneto, ls=':', color='grey')\n",
    "plt.ylabel('fitted precipitation factor')\n",
    "plt.xlabel('mean daily winter precipitation (kg m-2)') # mean over 1979-2020\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalibrate melt_f with the new pf!\n",
    "pf = fit_prcp_fac_aneto\n",
    "melt_f_opt_0_5_m = scipy.optimize.brentq(minimize_bias_geodetic, 10, 1000,\n",
    "                                     xtol=0.01, args=(mb_mod_monthly_0_5_m,\n",
    "                                                      mb_geodetic,\n",
    "                                                      h, w, pf, False,\n",
    "                                                      years,\n",
    "                                                      False, True, # do spinup before\n",
    "                                                      ), disp=True)\n",
    "# change the melt_f to the newly calibrated one\n",
    "mb_mod_monthly_0_5_m.melt_f = melt_f_opt_0_5_m\n",
    "spec_0_5_m = mb_mod_monthly_0_5_m.get_specific_mb(year=years, heights=h, widths=w)\n",
    "# check if the calibration has worked as we expect:\n",
    "np.testing.assert_allclose(spec_0_5_m.mean(), mb_geodetic, rtol = 1e-4)\n",
    "print(melt_f_opt_0_5_m, pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(years, spec_0_5_m)\n",
    "plt.ylabel('specific mass-balance')\n",
    "plt.xlabel('years')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more details about the applied surface type distinction method to get a melt factor that distinguishes between ice and snow age:\n",
    "\n",
    "inside of `TIModel_Sfc_Type`, there is **a surface type distinction model included with a bucket system together with a melt_f that varies with age** :\n",
    "- there are two options included at the moment:\n",
    "    - `melt_f_update=annual`\n",
    "        - If annual, then it uses 1 snow\n",
    "            and 5 firn buckets with yearly melt factor updates.\n",
    "    - `melt_f_update=monthly`:\n",
    "        -  If monthly, each month the snow is ageing over 6 years (i.e., 72 months -> 72 buckets).\n",
    "        \n",
    "        FRA I DON'T GET THIS\n",
    "    - the ice bucket is thought as an \"infinite\" bucket (because we do not know the ice thickness at this model stage)\n",
    "    - Melt factors are interpolated either:\n",
    "        - linearly inbetween the buckets.\n",
    "        - or using a negativ exponential change assumption with an e-folding change assumption of e.g. 0.5 or 1 year\n",
    "- default is to use a **spinup** of 6 years. So to compute the specific mass balance between 2000 and 2020, with `spinup=True`, the annual mb is computed since 1994 where at first everything is ice, and then it accumulates over the next years, so that in 2000 there is something in each bucket ...\n",
    "    - if we start in 1979 (start of W5E5), we neglect the spinup because we don't have climate data before 1979\n",
    "\n",
    "- the ratio of snow melt factor to ice melt factor is set to 0.5 (as in GloGEM) but it can be changed via `melt_f_ratio_snow_to_ice`\n",
    "    - if we set `melt_f_ratio_snow_to_ice=1` the melt factor is equal for all buckets, hence the results are equal to no surface type distinction (as in `TIModel`)\n",
    "- `get_annual_mb` and `get_monthly_mb` work as in PastMassBalance, however they only accept the height array that corresponds to the inversion height (so no mass-balance elevation feedback can be included at the moment!)\n",
    "    - that means the given mass-balance is the mass-balance over the inversion heights (before doing the inversion and so on)\n",
    "- the buckets are automatically updated when using `get_annual_mb` or `get_monthly_mb` via the `TIModel_Sfc_Type.pd_bucket` dataframe \n",
    "- to make sure that we do not compute mass-balance twice and to always have a spin-up of 6 years, the mass balance is automatically saved under \n",
    "    - `get_annual_mb.pd_mb_annual`: for each year\n",
    "        - when using `get_monthly_mb` for several years, after computing the December month, the `pd_mb_annual` dataframe is updated\n",
    "    - `get_annual_mb.pd_mb_monthly`: for each month \n",
    "        - note that this stays empty if we only use get_annual_mb with annual melt_f_update\n",
    "        \n",
    "        \n",
    "**-> you will use melt_f_update=monthly, spinup=True, melt_f_ratio_snow_to_ice=0.5, a negativ exponential change assumption with an e-folding change assumption of 1 year (see more details in the following plots below)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first 6 years are the spinup\n",
    "mb_mod_monthly_0_5_m.pd_mb_monthly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first 6 years are the spinup\n",
    "mb_mod_monthly_0_5_m.pd_mb_annual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_mod_monthly_0_5_m.pd_bucket "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example plot with monthly melt_f update:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = mb_mod_monthly_0_5_m\n",
    "name = '0_5_m_neg_exp_tau1yr'\n",
    "mb.get_specific_mb(year=years, heights=h, widths=w)\n",
    "mb_annual_dict_name = {}\n",
    "for y in years: # compute mass in kg\n",
    "    mb_y = mb.pd_mb_annual[y]  # output is in m of ice per second ! (would be the same as doing `mb.get_annual_mb(h, y)`)\n",
    "    mb_y = mb_y * mb.SEC_IN_YEAR * mb.rho\n",
    "    mb_y[17] = -1\n",
    "    mb_gradient,_,_,_,_ = scipy.stats.linregress(h[mb_y<0], y=mb_y[mb_y<0]) \n",
    "    mb_annual_dict_name[y] = mb_y\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.figure(figsize=(24, 8))\n",
    "lw=2\n",
    "plt.subplot(121)\n",
    "plt.title('melt_f change with ageing surface\\nfrom snow to firn to ice')\n",
    "ax = plt.gca()\n",
    "plt.text(-0.15,1.02,'(a)', transform=ax.transAxes)\n",
    "\n",
    "meltis = []\n",
    "for _,m in mb_mod_monthly_0_5_m.melt_f_buckets.items():\n",
    "    meltis.append(m)\n",
    "for m in np.arange(0,12):\n",
    "    meltis.append(mb_mod_monthly_0_5_m.melt_f)\n",
    "    \n",
    "plt.plot(np.arange(0,7.01,1/12), meltis, color='red', label='sfc type distinction, monthly update\\nneg_exp tau=1yr,\\nmelt_f of ice={:1.0f}, prcp_fac={:.2f}'.format(melt_f_opt_0_5_m, fit_prcp_fac_aneto))\n",
    "# plt.plot(np.arange(0,7.01,1/12), meltis, color='red', label='sfc type distinction, monthly update\\nexp. change (tau=1yr), melt_f={:0.1f}'.format(melt_f_opt_0_5_m_neg_exp_tau1yr))\n",
    "plt.xticks(np.arange(0,7.1,1))\n",
    "\n",
    "\n",
    "plt.xlabel('snow age (in years)')\n",
    "#plt.yticks(np.arange(0,1250,300,350,400,450,500,550])\n",
    "plt.ylabel(r'melt_f (mm w.e. K$^{-1}$ mth$^{-1}$)')\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# sort both labels and handles by labels\n",
    "labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "ax.legend(handles, labels)\n",
    "plt.axvline(6, color='grey', ls='--', alpha=0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "ax = plt.gca()\n",
    "plt.text(-0.15,1.02,'(b)', transform=ax.transAxes)\n",
    "plt.plot(pd.DataFrame(mb_annual_dict_name).mean(axis=1).values,\n",
    "         h, color = 'blue', \n",
    "         lw=lw)\n",
    "\n",
    "plt.title('mean MB profile (here: 2011-2020)')\n",
    "plt.xlabel('kg m-2')\n",
    "plt.ylabel('altitude (m)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also just look at seasonal MB profiles\n",
    "mb.reset_pd_mb_bucket()\n",
    "mb_grad_dict_name = []\n",
    "mb_monthly_dict_name = {}\n",
    "bucket_name = {}\n",
    "for y in years:\n",
    "    for m in np.arange(1,13,1):\n",
    "        floatyr = date_to_floatyear(y,m)\n",
    "        #if name != '0_5_m':\n",
    "        _, bucket_name[floatyr] = mb.get_monthly_mb(h, year=floatyr, bucket_output =True)\n",
    "        mb_m = mb.pd_mb_monthly[floatyr]  # output is in m of ice per second !\n",
    "        try:\n",
    "            mb_gradient,_,_,_,_ = scipy.stats.linregress(h[mb_m<0], y=mb_m[mb_m<0]) \n",
    "        except:\n",
    "            mb_gradient = np.NaN\n",
    "        mb_monthly_dict_name[floatyr] = mb_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## also get winter / summer MB profiles\n",
    "y0 = 1980 \n",
    "m_winter_mb = [10,11,12,1,2,3,4]\n",
    "m_summer_mb = [5,6,7,8,9]\n",
    "yr_changes = True\n",
    "m_start = 10\n",
    "add_climate = True\n",
    "ratio = 1\n",
    "melt_m_10 = {}\n",
    "melt_m_4 = {}\n",
    "melt_m_5 = {}\n",
    "mb_grad_winter = {}\n",
    "mb_grad_summer = {}\n",
    "mb_grad_winter_melt = {}\n",
    "mb_grad_summer_melt = {}\n",
    "color_dict = {'1_a': 'black', '0_5_m':'blue', '0_5_m_neg_exp':'red'}\n",
    "fig_w, axs_w = plt.subplots(1,7, figsize=(24,8), sharey=True, sharex=True)\n",
    "plt.suptitle('monthly MB profiles')\n",
    "\n",
    "fig_s, axs_s = plt.subplots(1,7, figsize=(24,8), sharey=True, sharex=True)\n",
    "\n",
    "mb.reset_pd_mb_bucket()\n",
    "_ = mb.get_specific_mb(h, widths=w, year=np.arange(1979,2020,1))\n",
    "\n",
    "pd_winter_mb = pd.DataFrame(index=h, columns=np.arange(y0,2020,1))\n",
    "pd_summer_mb = pd.DataFrame(index=h, columns=np.arange(y0,2020,1))\n",
    "pd_winter_melt = pd.DataFrame(index=h, columns=np.arange(y0,2020,1))\n",
    "pd_summer_melt = pd.DataFrame(index=h, columns=np.arange(y0,2020,1))\n",
    "# Let's plot monthly MB profiles of that year!!\n",
    "for year in np.arange(y0, 2020,1):\n",
    "    mbs_winter = 0\n",
    "    mbs_summer = 0\n",
    "    prcp_sol_winter = 0\n",
    "    prcp_sol_summer = 0\n",
    "\n",
    "    for j,m in enumerate(m_winter_mb):\n",
    "        if (m in np.arange(m_start, 13, 1)) and (yr_changes):\n",
    "            floatyr = utils.date_to_floatyear(year-1, m)\n",
    "        else:\n",
    "            floatyr = utils.date_to_floatyear(year, m)\n",
    "        out = mb.get_monthly_mb(h, year=floatyr, add_climate=True)\n",
    "        out, t, tfm, prcp, prcp_sol = out\n",
    "        mbs_winter += out * ratio\n",
    "        prcp_sol_winter += prcp_sol *ratio\n",
    "        if (year== 2008 and m>=10) or (year == 2009 and m<10):\n",
    "            try:\n",
    "                if m == 10 and year == 2008:\n",
    "                    melt_m_10[name] = out*mb.SEC_IN_MONTH * mb.rho-prcp_sol\n",
    "                elif m == 4 and year == 2009:\n",
    "                    melt_m_4[name] = out*mb.SEC_IN_MONTH * mb.rho-prcp_sol\n",
    "                axs_w[j].plot(out*mb.SEC_IN_MONTH *mb.rho, h)\n",
    "                axs_w[j].set_title(f'month: {m}')\n",
    "            except:\n",
    "                pass\n",
    "        #mbs_winter += mb_winter_m\n",
    "    for jj, m in enumerate(m_summer_mb):\n",
    "        floatyr = utils.date_to_floatyear(year, m)\n",
    "        out = mb.get_monthly_mb(h, year=floatyr, add_climate=True)\n",
    "        out, t, tfm, prcp, prcp_sol = out\n",
    "        mbs_summer += out * ratio\n",
    "        prcp_sol_summer += prcp_sol *ratio\n",
    "        if (year== 2008 and m>=10) or (year == 2009 and m<10):\n",
    "            try:\n",
    "                if m == 5 and year == 2009:\n",
    "                    melt_m_5[name] = out*mb.SEC_IN_MONTH * mb.rho-prcp_sol\n",
    "            except:\n",
    "                pass\n",
    "        if year == 2009:\n",
    "            try:\n",
    "                axs_s[jj].plot(out*mb.SEC_IN_MONTH * mb.rho, h)\n",
    "                axs_s[jj].set_title(f'month: {m}')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "    mbs_winter = mbs_winter * mb.SEC_IN_MONTH * mb.rho\n",
    "    mbs_summer = mbs_summer * mb.SEC_IN_MONTH * mb.rho\n",
    "\n",
    "    pd_winter_mb.loc[h, year] = mbs_winter\n",
    "    pd_summer_mb.loc[h, year] = mbs_summer\n",
    "\n",
    "    pd_winter_melt.loc[h, year] = mbs_winter-prcp_sol_winter\n",
    "    pd_summer_melt.loc[h, year] = mbs_summer-prcp_sol_summer\n",
    "\n",
    "\n",
    "\n",
    "mb_grad_winter[name] = pd_winter_mb.mean(axis=1).values, pd_winter_mb.mean(axis=1).index\n",
    "mb_grad_summer[name] = pd_summer_mb.mean(axis=1).values, pd_summer_mb.mean(axis=1).index\n",
    "\n",
    "mb_grad_winter_melt[name] = pd_winter_melt.mean(axis=1).values, pd_winter_melt.mean(axis=1).index\n",
    "mb_grad_summer_melt[name] = pd_summer_melt.mean(axis=1).values, pd_summer_melt.mean(axis=1).index\n",
    "\n",
    "axs_s[0].set_ylabel('altitude (m)')\n",
    "axs_w[0].set_ylabel('altitude (m)')\n",
    "axs_s[0].set_xlabel('kg m-2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=1\n",
    "temp, tfm, prcp, prcp_solid = mb.get_monthly_climate(h, year=utils.date_to_floatyear(2009, m))\n",
    "temp, tfm, prcp, prcp_solid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '0_5_a'\n",
    "fig, axs = plt.subplots(4, 3, #gridspec_kw={'width_ratios': [1,1,1]},\n",
    "                        figsize=(24, 24),\n",
    "                       constrained_layout=True, sharey=True)\n",
    "\n",
    "for j,m in enumerate([10,11,12,1,2,3,4,5,6,7,8,9]):\n",
    "    if m in [10,11,12]:\n",
    "        k = 0\n",
    "    elif m in [1,2,3]:\n",
    "        k=1\n",
    "        j = j-3\n",
    "    elif m in [4,5,6]:\n",
    "        k=2\n",
    "        j = j-6\n",
    "    else:\n",
    "        k=3\n",
    "        j=j-9\n",
    "    ax = axs[k,j]\n",
    "    ax.set_facecolor('gainsboro')\n",
    "    if m >= 10:\n",
    "        year = 2017#9 # 2001\n",
    "    else:\n",
    "        year = 2018 #10 # 2000\n",
    "\n",
    "    floatyr = utils.date_to_floatyear(year, m)\n",
    "    \n",
    "    sns_pd_bucket_sel = bucket_name[floatyr].copy()\n",
    "    sns_pd_bucket_sel['altitude (m)'] = h.round(1)\n",
    "    sns_pd_bucket_sel = sns_pd_bucket_sel[sns_pd_bucket_sel.columns[::-1]]\n",
    "    \n",
    "    sns_pd_bucket_sel.index = bucket_name[floatyr].index #sns_pd_bucket_sel['altitude (m)']\n",
    "    # only plot every second altitude band !!! \n",
    "    sns_pd_bucket_sel = sns_pd_bucket_sel.iloc[::2]\n",
    "    pd_pivot = sns_pd_bucket_sel[sns_pd_bucket_sel.columns[2:]]\n",
    "    pd_pivot.index = pd_pivot.index/1000\n",
    "    pd_pivot = pd_pivot.sort_index(ascending=False)\n",
    "\n",
    "    pd_pivot.plot.barh(stacked=True, ax= ax,\n",
    "                       colormap='Blues_r', \n",
    "                       )\n",
    "\n",
    "    han, lab = ax.get_legend_handles_labels()\n",
    "    ax.get_legend().remove()\n",
    "    if j == 0:\n",
    "        ax.legend(handles = [han[k-1] for k in [12, 24, 36, 48, 60, 72]],\n",
    "                  labels = [lab[k-1] for k in [12, 24, 36, 48, 60, 72]],\n",
    "                  title='snow age (<72 months)',  loc = 4, framealpha = 0.4, ncol=6,\n",
    "                  bbox_to_anchor=(1,0.05),\n",
    "                  labelspacing=0.1, handlelength=1, handletextpad=0.3, columnspacing=0.9);\n",
    "        ax.set_ylabel('distance along flowline (km)')\n",
    "    \n",
    "    ax.set_xlabel(r'firn or snow above ice (kg m$^{-2}$)')\n",
    "    ax.set_title(f'm={m}', fontsize=18)\n",
    "    if m>= 10:\n",
    "        ax.text(0.77,0.012, 'year=2017', transform=ax.transAxes)\n",
    "    else:\n",
    "        ax.text(0.77,0.012, 'year=2018', transform=ax.transAxes)\n",
    "    if j == 2:\n",
    "        ax2 = ax.twinx()\n",
    "        pd_pivot.plot.barh(stacked=True, ax= ax2,\n",
    "                   colormap='Blues_r', alpha = 0,\n",
    "                   )\n",
    "        ax2.set_yticklabels(h[::2].round(0).astype(int)[::-1])\n",
    "        ax2.set_ylabel('altitude (m)')\n",
    "        ax2.get_legend().remove()\n",
    "    ax.set_xlim([0,2500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w\n",
    "melt_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = kwargs_for_TIModel_Sfc_Type.copy()\n",
    "kwargs['mb_type'] = mb_type\n",
    "kwargs['grad_type'] = grad_type\n",
    "#kwargs['melt_f'] = melt_f_opt_0_5_m\n",
    "#kwargs['prcp_fac'] = fit_prcp_fac_aneto\n",
    "fs_new = '_{}_sfc_type_{}_{}_{}'.format(baseline_climate, melt_f_change, mb_type, grad_type)\n",
    "d = {'melt_f': melt_f_opt_0_5_m,\n",
    "     'pf': fit_prcp_fac_aneto,\n",
    "     'temp_bias': 0}\n",
    "gdir.write_json(d, filename='melt_f_geod', filesuffix=fs_new)\n",
    "\n",
    "from MBsandbox.mbmod_daily_oneflowline import compile_fixed_geometry_mass_balance_TIModel\n",
    "#filesuffix = f'_gcm_{ensemble}_{ssp}_sfc_type_{sfc_type}_{mb_type}_{grad_type}_historical_test'\n",
    "climate_filename = 'climate_historical'\n",
    "climate_input_filesuffix = 'W5E5' #daily\n",
    "out_hist = compile_fixed_geometry_mass_balance_TIModel(gdir, filesuffix='historical_W5E5_test',\n",
    "                                            climate_filename = climate_filename,\n",
    "                                            path=True, csv=True,\n",
    "                                            use_inversion_flowlines=False,\n",
    "                                            climate_input_filesuffix = climate_input_filesuffix,\n",
    "                                            ys=2011, ye=2020, \n",
    "                                            from_json=True,\n",
    "                                            json_filename='melt_f_geod',\n",
    "                                            sfc_type=melt_f_change,\n",
    "                                            **kwargs)\n",
    "# this should be again equal to the observations (as we calibrated it to match)\n",
    "np.testing.assert_allclose(out_hist.mean(), pd_geodetic.loc[gdir.rgi_id].dmdtda*1000, rtol=1e-3)\n",
    "#np.testing.assert_allclose(out['RGI60-11.00897'].mean(), -1100.3, rtol = 1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "705f036afebab14ba3958dfbf5720c1e1e37a03d5afe33574ff09620abf8737d"
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
